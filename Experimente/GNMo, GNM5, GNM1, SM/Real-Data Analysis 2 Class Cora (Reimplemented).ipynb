{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset on harddrive.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "\n",
    "from GNM_Toolbox.tools.tools import *\n",
    "from GNM_Toolbox.gnm import *\n",
    "from GNM_Toolbox.data.dataloader import *\n",
    "\n",
    "dataset = load_dataset('Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# Gesucht wird eine Liste l von Indizes, sodass für i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][0])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][0])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def h(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi_test(X, y):\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(35.)), 1, 1.6\n",
    "    return torch.sigmoid(a0 + a1 * h(X) + a2 * y)\n",
    "\n",
    "def pi_complicated(X, y):\n",
    "    tmp = torch.sum(X,axis=1) \n",
    "    h = torch.exp(tmp/13-4)-(tmp-15)/15\n",
    "    pi = 1/(1+35*np.exp(h[:]-1.6*y[:]))\n",
    "    return pi\n",
    "\n",
    "def pi_simple(x, y):\n",
    "    a = 0\n",
    "    b = 1\n",
    "    return torch.sigmoid(a + b*y)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def calculate_lambda(train_mask, y):\n",
    "    a = 0 # Anzahl an Klasse 0\n",
    "    b = 0 # Anzahl an Klasse 1\n",
    "    for yy in y[train_mask]:\n",
    "        if yy == 0:\n",
    "            a += 1\n",
    "        elif yy == 1:\n",
    "            b += 1\n",
    "    return b/a\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "data.num_classes = 2\n",
    "# Klassen 0,1,2,4,5,6 werden zu Klasse 1, Klasse 3 wird zu Klasse 0\n",
    "y = torch.zeros_like(data.y)\n",
    "y[data.y == 3] = 1\n",
    "data.y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Fitting Train and Val Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find masks such that lambda has specific values\n",
    "targets = [1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5]\n",
    "masks = dict()\n",
    "fitting_masks = dict()\n",
    "targets_done = set()\n",
    "worst_allowed_diff = 0.005\n",
    "worst_diff = 1\n",
    "num_masks = 40 # num_masks_per_lambda\n",
    "\n",
    "for t in targets:\n",
    "    masks[t] = list()\n",
    "    fitting_masks[t] = 0\n",
    "    \n",
    "#pickle_write('m_masks.pkl', (masks, fitting_masks, targets_done))\n",
    "\n",
    "def print_fitting(fitting_masks, i):\n",
    "    k = fitting_masks.keys()\n",
    "    string = ''\n",
    "    for kk in k:\n",
    "        if fitting_masks[kk] <= 40:\n",
    "            string += ' {}'.format(fitting_masks[kk])\n",
    "        else:\n",
    "            string += ' 40+'\n",
    "    print(string + ' at iteration {}'.format(i), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "masks, fitting_masks, targets_done = pickle_read('m_masks.pkl')\n",
    "i = 0\n",
    "t_start = time.time()\n",
    "while worst_diff > worst_allowed_diff and i < 40000 and len(set(targets)-targets_done) > 0:\n",
    "    i += 1\n",
    "    known_mask = create_mask_from_pi(data, pi_complicated)\n",
    "    val_mask, train_mask = split_known_mask_into_val_and_train_mask(known_mask)\n",
    "    l = calculate_lambda(train_mask, data.y)\n",
    "    item = (l, train_mask, val_mask)\n",
    "    \n",
    "    # Update masks\n",
    "    for t in set(targets)-targets_done:\n",
    "        diff = abs(l - t)\n",
    "        masks_ind = masks[t]\n",
    "        if len(masks_ind) < num_masks:\n",
    "            insert_into_list(masks_ind, item, t)\n",
    "            if diff < worst_allowed_diff:\n",
    "                fitting_masks[t] += 1\n",
    "                #print_fitting(fitting_masks, i)\n",
    "                if fitting_masks[t] > 40:\n",
    "                    targets_done.add(t)\n",
    "        elif abs(masks_ind[num_masks-1][0] - t) > diff:\n",
    "            insert_into_list(masks_ind, item, t)\n",
    "            masks[t] = masks_ind[0:num_masks]\n",
    "            if diff < worst_allowed_diff:\n",
    "                fitting_masks[t] += 1\n",
    "                print_fitting(fitting_masks, i)\n",
    "                if fitting_masks[t] > 40:\n",
    "                    targets_done.add(t)\n",
    "    \n",
    "    # Update worst_diff\n",
    "    worst_diff_old = worst_diff\n",
    "    worst_diff = 0\n",
    "    for t in set(targets)-targets_done:\n",
    "        length = len(masks[t])\n",
    "        diff = abs(t - masks[t][length-1][0])\n",
    "        if diff > worst_diff:\n",
    "            worst_diff = diff\n",
    "            \n",
    "# Safe masks\n",
    "pickle_write('m_masks.pkl', (masks, fitting_masks, targets_done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masks\n",
    "all_masks,_,_ = pickle_read('m_masks.pkl')\n",
    "subset = [1.2, 1.5, 1.7, 2, 2.2]\n",
    "choosen_masks = {k: all_masks[k] for k in subset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637/1000) |████████████        | (22h 24min 50sec|12h 47min 34sec|2min 6sec)))\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-de558836cfa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNB_masks\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mIT_per_mask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mIT_per_mask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNB_masks\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mIT_per_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mgnm_models_one_net_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_net_with_gnm_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mgnm_models_one_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_net_with_gnm_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mgnm_models_5_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_net_with_gnm_new_model_each_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0msm_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_one_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/20 SS/Bachelorarbeit/Python/GNM_Toolbox/gnm.py\u001b[0m in \u001b[0;36mtrain_net_with_gnm_one_model\u001b[0;34m(data, train_mask, val_mask, classification, nety, neth, h_out_features, pi, logging, NB_IT_0, NB_IT_1, NB_EPOCHS, PATIENCE, epsilon, B)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mmodely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0moptimizerY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/20 SS/Bachelorarbeit/Python/GNM_Toolbox/tools/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__distribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__aggr_params__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mupdate_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__distribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_params__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0;32m--> 299\u001b[0;31m                            reduce=self.aggr)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Real Data analysis with different GNMs and SM\n",
    "IT_per_mask = 5\n",
    "NB_masks = len(choosen_masks[1.5])\n",
    "M = len(choosen_masks)\n",
    "t_0 = time.time()\n",
    "\n",
    "all_models = dict()\n",
    "\n",
    "# Iteriere über Masken\n",
    "for i, l in enumerate(choosen_masks):\n",
    "    gnm_models_one_net_optimized = list()\n",
    "    gnm_models_one_net = list()\n",
    "    gnm_models_5_nets = list()\n",
    "    sm_models = list()\n",
    "    for j, mask_tupel in enumerate(choosen_masks[l]):\n",
    "        _, train_mask, val_mask = mask_tupel\n",
    "\n",
    "        # Trainiere jeweils N Modelle\n",
    "        for k in range(IT_per_mask):\n",
    "            print_status(i * NB_masks * IT_per_mask + j * IT_per_mask + k, M * NB_masks * IT_per_mask, t_0)\n",
    "            gnm_models_one_net_optimized.append((*train_net_with_gnm_one_model(data, train_mask, val_mask)[1:], j))\n",
    "            gnm_models_one_net.append((*train_net_with_gnm_one_model(data, train_mask, val_mask)[1:], j))\n",
    "            gnm_models_5_nets.append((*train_net_with_gnm_new_model_each_epoch(data, train_mask, val_mask)[1:], j))\n",
    "            sm_models.append((*train_one_net(data, train_mask, val_mask)[1:], j))\n",
    "    all_models[l] = (gnm_models_one_net_optimized, gnm_models_one_net, gnm_models_5_nets, sm_models)\n",
    "    pickle_write('real-data-results-final-part-{}.pkl'.format(i), all_models)\n",
    "    \n",
    "pickle_write('real-data-results-final.pkl', all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(*(1, 2, 3), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
