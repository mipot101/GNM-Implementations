{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset on harddrive.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "\n",
    "from GNM_Toolbox.tools.tools import *\n",
    "from GNM_Toolbox.gnm import *\n",
    "from GNM_Toolbox.data.dataloader import *\n",
    "\n",
    "dataset = load_dataset('Citeseer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# out_list darf tupel beliebiger Länge haben. \n",
    "# Gesucht wird eine Liste l von Indizes, sodass für i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list, idx = 0):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][idx])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][idx])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def h(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi(X, y):\n",
    "    y0 = F.one_hot(y, 6)\n",
    "    # y should be one-hot encoded\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(20.)), 1, torch.tensor([[5, 0.5, 0.2, 1, 0.5, 2]]).view((6, 1))\n",
    "    return torch.sigmoid(a0 + a1 * h(X).view((-1, 1)) + y0.type(torch.float) @ a2)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def count_classes(y, mask):\n",
    "    l = np.zeros((max(y)+1))\n",
    "    for yy in y[mask]:\n",
    "        l[yy] += 1\n",
    "    return l\n",
    "\n",
    "def calc_variance(y, mask):\n",
    "    y_distribution = count_classes(y, mask)\n",
    "    return np.var(y_distribution)\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)\n",
    "\n",
    "def disturb_y(y, probability): # y must have 2 classes\n",
    "    y_dis = torch.zeros_like(y)\n",
    "    for i in range(len(y)):\n",
    "        if np.random.rand(1) < probability:\n",
    "            y_dis[i] = 0 if np.random.rand(1) > 0.5 else 1\n",
    "        else:\n",
    "            y_dis[i] = y[i]\n",
    "                \n",
    "    return F.one_hot(y_dis, 2)\n",
    "\n",
    "# root mean squared error\n",
    "def RMSE(pi_est, pi_true):\n",
    "    return torch.sqrt(F.mse_loss(pi_true, pi_est.view(pi_true.shape)))\n",
    "\n",
    "# mean squared error\n",
    "def MSE(pi_est, pi_true):\n",
    "    return F.mse_loss(pi_true, pi_est)\n",
    "\n",
    "# weighted mean squared error\n",
    "def WMSE(pi_est, pi_true, weight):\n",
    "    return torch.mean(weight * (pi_est - pi_true) ** 2)\n",
    "\n",
    "\n",
    "# mean root error\n",
    "def MRE(pi_est, pi_true):\n",
    "    return torch.mean(torch.pow(abs(pi_est.view(pi_true.shape) - pi_true), 0.5))\n",
    "\n",
    "# berechnet Gewichtungen für weighted mean square error\n",
    "def calc_inverse_weights(pi_real):\n",
    "    bins = torch.zeros(len(pi_real)).type(torch.float)\n",
    "    pi = pi_real.detach().numpy()\n",
    "    # Count \n",
    "    for p in pi_real:\n",
    "        bins[int(p*100)] += 1\n",
    "    bins = 1/bins\n",
    "    bins[bins == (torch.tensor(1.)/0)] = 999999999\n",
    "    return torch.sqrt(bins)\n",
    "\n",
    "def eval_pi(pi_true, pi_est, diff=0.01):\n",
    "    pi_diff = abs(pi_true.view(pi_est.shape)-pi_est)\n",
    "    pi_binar = [(p < diff) for p in pi_diff]\n",
    "    return sum(pi_binar)/(1. * pi_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "data.num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\r"
     ]
    }
   ],
   "source": [
    "masks = list()\n",
    "i = 0\n",
    "while i < 4000:\n",
    "    mask = create_mask_from_pi(data, pi)\n",
    "    val_mask, train_mask = split_known_mask_into_val_and_train_mask(mask)\n",
    "    l = calc_variance(data.y, train_mask)\n",
    "    if l > 0:\n",
    "        masks.append([train_mask, val_mask, l])\n",
    "        i += 1\n",
    "        print(i, end='\\r')\n",
    "masks.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.299777777777784, 24.229640376822008)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas = list()\n",
    "for mask in masks:\n",
    "    lambdas.append(mask[2])\n",
    "plt.hist(lambdas, 80);\n",
    "np.mean(lambdas), np.std(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "targets = np.linspace(10, 120, 200) # choose masks depending on lambdas\n",
    "idxs = find_each_nearest(targets, masks, idx=2)\n",
    "idxs = list(dict.fromkeys(idxs)) # remove duplicates\n",
    "print(len(idxs))\n",
    "choosen_masks = [masks[i] for i in idxs]\n",
    "#pickle_write('algorithm-analysis-citeseer-6-masks.pkl', choosen_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pickle_read('algorithm-analysis-citeseer-6-masks.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval \n",
    "NB_masks = 200\n",
    "choosen_masks = masks[::-1]\n",
    "IT_PER_MASK = 2\n",
    "M = len(choosen_masks)\n",
    "all_models = None\n",
    "if False:\n",
    "    all_models = pickle_read('algorithm-analysis-citeseer-6.pkl')\n",
    "else:\n",
    "    all_models = {'sm': list(), 'gnm': list(), 'gnmi': list()}\n",
    "    \n",
    "sm_models = all_models['sm']\n",
    "gnm_models = all_models['gnm']\n",
    "gnmi_models = all_models['gnmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/400) |████████████████████| (6h 37min 47sec|59.82sec|59.82sec)                                        \r"
     ]
    }
   ],
   "source": [
    "# Iteriere über Masken\n",
    "t_0 = time.time()\n",
    "for j, mask_tupel in enumerate(choosen_masks):\n",
    "    train_mask, val_mask, l = mask_tupel\n",
    "\n",
    "    # Trainiere jeweils N Modelle\n",
    "    for k in range(IT_PER_MASK):\n",
    "        print_status(j * IT_PER_MASK + k, M * IT_PER_MASK, t_0)\n",
    "        \n",
    "        try:\n",
    "            t = time.time()\n",
    "            _, _, acc_list = train_net_with_gnm(data, train_mask, val_mask)\n",
    "            gnm_models.append([l, acc_list[-1], time.time()-t])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            \n",
    "        try:\n",
    "            t = time.time()\n",
    "            _, _, acc_gnmi = train_net_with_gnm_improved(data, train_mask, val_mask)\n",
    "            gnmi_models.append([l, acc_gnmi, time.time()-t])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            _, _, acc_sm, _ = train_one_net(data, train_mask, val_mask)\n",
    "            sm_models.append([l, acc_sm])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_models = {'gnm': gnm_models, 'gnmi': gnmi_models, 'sm': sm_models}\n",
    "        pickle_write('algorithm-analysis-citeseer-6.pkl', all_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
