{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset on harddrive.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "\n",
    "from GNM_Toolbox.tools.tools import *\n",
    "from GNM_Toolbox.gnm import *\n",
    "from GNM_Toolbox.data.dataloader import *\n",
    "\n",
    "dataset = load_dataset('Citeseer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# out_list darf tupel beliebiger Länge haben. \n",
    "# Gesucht wird eine Liste l von Indizes, sodass für i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list, idx = 0):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][idx])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][idx])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def h(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi(X, y):\n",
    "    y0 = F.one_hot(y, 6)\n",
    "    # y should be one-hot encoded\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(20.)), 1, torch.tensor([[5, 0.5, 0.2, 1, 0.5, 2]]).view((6, 1))\n",
    "    return torch.sigmoid(a0 + a1 * h(X).view((-1, 1)) + y0.type(torch.float) @ a2)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def count_classes(y, mask):\n",
    "    l = np.zeros((max(y)+1))\n",
    "    for yy in y[mask]:\n",
    "        l[yy] += 1\n",
    "    return l\n",
    "\n",
    "def calc_variance(y, mask):\n",
    "    y_distribution = count_classes(y, mask)\n",
    "    return np.var(y_distribution)\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)\n",
    "\n",
    "def disturb_y(y, probability): # y must have 2 classes\n",
    "    y_dis = torch.zeros_like(y)\n",
    "    for i in range(len(y)):\n",
    "        if np.random.rand(1) < probability:\n",
    "            y_dis[i] = 0 if np.random.rand(1) > 0.5 else 1\n",
    "        else:\n",
    "            y_dis[i] = y[i]\n",
    "                \n",
    "    return F.one_hot(y_dis, 2)\n",
    "\n",
    "# root mean squared error\n",
    "def RMSE(pi_est, pi_true):\n",
    "    return torch.sqrt(F.mse_loss(pi_true, pi_est.view(pi_true.shape)))\n",
    "\n",
    "# mean squared error\n",
    "def MSE(pi_est, pi_true):\n",
    "    return F.mse_loss(pi_true, pi_est)\n",
    "\n",
    "# weighted mean squared error\n",
    "def WMSE(pi_est, pi_true, weight):\n",
    "    return torch.mean(weight * (pi_est - pi_true) ** 2)\n",
    "\n",
    "\n",
    "# mean root error\n",
    "def MRE(pi_est, pi_true):\n",
    "    return torch.mean(torch.pow(abs(pi_est.view(pi_true.shape) - pi_true), 0.5))\n",
    "\n",
    "# berechnet Gewichtungen für weighted mean square error\n",
    "def calc_inverse_weights(pi_real):\n",
    "    bins = torch.zeros(len(pi_real)).type(torch.float)\n",
    "    pi = pi_real.detach().numpy()\n",
    "    # Count \n",
    "    for p in pi_real:\n",
    "        bins[int(p*100)] += 1\n",
    "    bins = 1/bins\n",
    "    bins[bins == (torch.tensor(1.)/0)] = 999999999\n",
    "    return torch.sqrt(bins)\n",
    "\n",
    "def eval_pi(pi_true, pi_est, diff=0.01):\n",
    "    pi_diff = abs(pi_true.view(pi_est.shape)-pi_est)\n",
    "    pi_binar = [(p < diff) for p in pi_diff]\n",
    "    return sum(pi_binar)/(1. * pi_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "data.num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\r"
     ]
    }
   ],
   "source": [
    "masks = list()\n",
    "i = 0\n",
    "while i < 4000:\n",
    "    mask = create_mask_from_pi(data, pi)\n",
    "    val_mask, train_mask = split_known_mask_into_val_and_train_mask(mask)\n",
    "    l = calc_variance(data.y, train_mask)\n",
    "    if l > 0:\n",
    "        masks.append([train_mask, val_mask, l])\n",
    "        i += 1\n",
    "        print(i, end='\\r')\n",
    "masks.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,   3.,   7.,  11.,  12.,  22.,  29.,  31.,  45.,  57.,  63.,\n",
       "         69.,  95.,  78.,  84.,  93., 105., 121., 111., 121., 137., 144.,\n",
       "        132., 133., 141., 115., 139., 131., 124., 112., 107., 118.,  95.,\n",
       "        105.,  91.,  81.,  87.,  87.,  75.,  60.,  65.,  56.,  53.,  49.,\n",
       "         43.,  37.,  33.,  28.,  30.,  17.,  29.,  22.,  15.,  24.,  12.,\n",
       "         13.,  14.,   8.,   9.,   8.,   5.,   8.,   7.,   5.,   4.,   4.,\n",
       "          1.,   4.,   5.,   1.,   4.,   3.,   2.,   1.,   0.,   2.,   0.,\n",
       "          2.,   0.,   1.]),\n",
       " array([  6.47222222,   8.43298611,  10.39375   ,  12.35451389,\n",
       "         14.31527778,  16.27604167,  18.23680556,  20.19756944,\n",
       "         22.15833333,  24.11909722,  26.07986111,  28.040625  ,\n",
       "         30.00138889,  31.96215278,  33.92291667,  35.88368056,\n",
       "         37.84444444,  39.80520833,  41.76597222,  43.72673611,\n",
       "         45.6875    ,  47.64826389,  49.60902778,  51.56979167,\n",
       "         53.53055556,  55.49131944,  57.45208333,  59.41284722,\n",
       "         61.37361111,  63.334375  ,  65.29513889,  67.25590278,\n",
       "         69.21666667,  71.17743056,  73.13819444,  75.09895833,\n",
       "         77.05972222,  79.02048611,  80.98125   ,  82.94201389,\n",
       "         84.90277778,  86.86354167,  88.82430556,  90.78506944,\n",
       "         92.74583333,  94.70659722,  96.66736111,  98.628125  ,\n",
       "        100.58888889, 102.54965278, 104.51041667, 106.47118056,\n",
       "        108.43194444, 110.39270833, 112.35347222, 114.31423611,\n",
       "        116.275     , 118.23576389, 120.19652778, 122.15729167,\n",
       "        124.11805556, 126.07881944, 128.03958333, 130.00034722,\n",
       "        131.96111111, 133.921875  , 135.88263889, 137.84340278,\n",
       "        139.80416667, 141.76493056, 143.72569444, 145.68645833,\n",
       "        147.64722222, 149.60798611, 151.56875   , 153.52951389,\n",
       "        155.49027778, 157.45104167, 159.41180556, 161.37256944,\n",
       "        163.33333333]),\n",
       " <a list of 80 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas = list()\n",
    "for mask in masks:\n",
    "    lambdas.append(mask[2])\n",
    "plt.hist(lambdas, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "targets = np.linspace(10, 120, 200) # choose masks depending on lambdas\n",
    "idxs = find_each_nearest(targets, masks, idx=2)\n",
    "idxs = list(dict.fromkeys(idxs)) # remove duplicates\n",
    "print(len(idxs))\n",
    "choosen_masks = [masks[i] for i in idxs]\n",
    "#pickle_write('algorithm-analysis-citeseer-6-masks.pkl', choosen_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pickle_read('algorithm-analysis-citeseer-6-masks.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval \n",
    "NB_masks = 200\n",
    "choosen_masks = masks[::-1]\n",
    "IT_PER_MASK = 2\n",
    "M = len(choosen_masks)\n",
    "all_models = None\n",
    "if False:\n",
    "    all_models = pickle_read('algorithm-analysis-citeseer-6.pkl')\n",
    "else:\n",
    "    all_models = {'sm': list(), 'gnm': list(), 'gnmi': list()}\n",
    "    \n",
    "sm_models = all_models['sm']\n",
    "gnm_models = all_models['gnm']\n",
    "gnmi_models = all_models['gnmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/400) |████████████████████| (6h 37min 47sec|59.82sec|59.82sec)                                        \r"
     ]
    }
   ],
   "source": [
    "# Iteriere über Masken\n",
    "t_0 = time.time()\n",
    "for j, mask_tupel in enumerate(choosen_masks):\n",
    "    train_mask, val_mask, l = mask_tupel\n",
    "\n",
    "    # Trainiere jeweils N Modelle\n",
    "    for k in range(IT_PER_MASK):\n",
    "        print_status(j * IT_PER_MASK + k, M * IT_PER_MASK, t_0)\n",
    "        \n",
    "        try:\n",
    "            t = time.time()\n",
    "            _, _, acc_list = train_net_with_gnm(data, train_mask, val_mask)\n",
    "            gnm_models.append([l, acc_list[-1], time.time()-t])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            \n",
    "        try:\n",
    "            t = time.time()\n",
    "            _, _, acc_gnmi = train_net_with_gnm_improved(data, train_mask, val_mask)\n",
    "            gnmi_models.append([l, acc_gnmi, time.time()-t])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            _, _, acc_sm, _ = train_one_net(data, train_mask, val_mask)\n",
    "            sm_models.append([l, acc_sm])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_models = {'gnm': gnm_models, 'gnmi': gnmi_models, 'sm': sm_models}\n",
    "        pickle_write('algorithm-analysis-citeseer-6.pkl', all_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
