{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $L_2$ Improvement Cora 2-class\n",
    "\n",
    "Um dieses Experiment selbst auszuf端hren, f端hre die Zellen von oben nach unten aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "\n",
    "from GNM_Toolbox import *\n",
    "\n",
    "dataset = load_dataset('Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# Gesucht wird eine Liste l von Indizes, sodass f端r i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][0])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][0])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def h0(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi0(X, y):\n",
    "    y0 = F.one_hot(y, 2).type(X.dtype)\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(35.)), 1, torch.tensor([0, 1.6])\n",
    "    return torch.sigmoid(a0 + a1 * h0(X) + a2 @ y0.T)\n",
    "\n",
    "def h1(x):\n",
    "    a0, a1, a2, a3 = 18, 4, 5, 6\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi1(X, y):\n",
    "    y0 = F.one_hot(y, 2)\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(25.)), 2., torch.tensor([2, 4])\n",
    "    return torch.sigmoid(a0 + a1 * h1(X) + a2 @ y0.T)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def calculate_lambda(train_mask, y):\n",
    "    a = 0 # Anzahl an Klasse 0\n",
    "    b = 0 # Anzahl an Klasse 1\n",
    "    for yy in y[train_mask]:\n",
    "        if yy == 0:\n",
    "            a += 1\n",
    "        elif yy == 1:\n",
    "            b += 1\n",
    "    return b/a\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)\n",
    "\n",
    "def disturb_y(y, probability): # y must have 2 classes\n",
    "    y_dis = torch.zeros_like(y)\n",
    "    for i in range(len(y)):\n",
    "        if np.random.rand(1) < probability:\n",
    "            y_dis[i] = 0 if np.random.rand(1) > 0.5 else 1\n",
    "        else:\n",
    "            y_dis[i] = y[i]\n",
    "                \n",
    "    return F.one_hot(y_dis, 2)\n",
    "\n",
    "# root mean squared error\n",
    "def RMSE(pi_est, pi_true):\n",
    "    return torch.sqrt(F.mse_loss(pi_true, pi_est.view(pi_true.shape)))\n",
    "\n",
    "# mean squared error\n",
    "def MSE(pi_est, pi_true):\n",
    "    return F.mse_loss(pi_true, pi_est)\n",
    "\n",
    "# weighted mean squared error\n",
    "def WMSE(pi_est, pi_true, weight):\n",
    "    return torch.mean(weight * (pi_est - pi_true) ** 2)\n",
    "\n",
    "\n",
    "# mean root error\n",
    "def MRE(pi_est, pi_true):\n",
    "    return torch.mean(torch.pow(abs(pi_est.view(pi_true.shape) - pi_true), 0.5))\n",
    "\n",
    "# berechnet Gewichtungen f端r weighted mean square error\n",
    "def calc_inverse_weights(pi_real):\n",
    "    bins = torch.zeros(len(pi_real)).type(torch.float)\n",
    "    pi = pi_real.detach().numpy()\n",
    "    # Count \n",
    "    for p in pi_real:\n",
    "        bins[int(p*100)] += 1\n",
    "    bins = 1/bins\n",
    "    bins[bins == (torch.tensor(1.)/0)] = 999999999\n",
    "    return torch.sqrt(bins)\n",
    "\n",
    "def eval_pi(pi_true, pi_est, diff=0.01):\n",
    "    pi_diff = abs(pi_true.view(pi_est.shape)-pi_est)\n",
    "    pi_binar = [(p < diff) for p in pi_diff]\n",
    "    return sum(pi_binar)/(1. * pi_true.shape[0])\n",
    "\n",
    "def plot_data(all_models, colors, names):\n",
    "    M = len(all_models)\n",
    "    \n",
    "    # Set up distances\n",
    "    number_boxes = len(all_models[list(all_models.keys())[0]])\n",
    "    minDist = -0.4\n",
    "    maxDist = 0.4\n",
    "    dist = [minDist + (maxDist-minDist)/(number_boxes-1) * i for i in range(number_boxes)]\n",
    "    \n",
    "    # Set up \n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    ax = plt.axes()\n",
    "    minimum = 1\n",
    "    maximum = 0\n",
    "    for i, l in zip(range(1, M+1), all_models):\n",
    "        for models, color, (dd, d) in zip(all_models[l], colors, enumerate(dist)):\n",
    "            acc = list()\n",
    "            for model in models:\n",
    "                acc.append(model) \n",
    "            # Find min und max\n",
    "            if minimum > min(acc):\n",
    "                minimum = min(acc)\n",
    "            if maximum < max(acc):\n",
    "                maximum = max(acc)\n",
    "            alternative_boxplot(acc, i+d, 0.4/len(dist), color)\n",
    "        \n",
    "    # Set x-axis labels\n",
    "    seperation_lines = [i + 0.5 for i in range(1, M)]\n",
    "    plt.vlines(seperation_lines, 0, 1, colors='grey', linestyles='dashed')\n",
    "    ax.set_xticks([1 + d for d in dist])\n",
    "    #ax.set_yticks([0.005, 0.01, 0.015, 0.02, 0.03, 0.04, 0.05])\n",
    "    lambdas = list(all_models.keys())\n",
    "    lambdas.sort()\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.ylim(minimum - 0.01, maximum + 0.01)\n",
    "    plt.xlim(0.4, M + 0.6)\n",
    "    \n",
    "    # draw temporary red and blue lines and use them to create a legend\n",
    "    helps = list()\n",
    "    for color in colors:\n",
    "        h, = plt.plot([1, 1], color=color)\n",
    "        helps.append(h)\n",
    "    ax.grid(True, axis='y')\n",
    "    ax.set_xlabel(r'p', fontsize=20)\n",
    "    ax.set_ylabel(r'$L_2$', fontsize=20)\n",
    "    for h in helps:\n",
    "        h.set_visible(False)\n",
    "\n",
    "def alternative_boxplot(data, x_position, x_width, color):\n",
    "    # data: list of floats\n",
    "    # x_postition: float\n",
    "    # x_width: float\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    print('{}:{}'.format(sum([1 for d in data if d > mean]), sum([1 for d in data if d < mean])))\n",
    "    noise = np.random.rand(N)\n",
    "    x_positions = x_position - x_width/2. + noise * x_width\n",
    "    plt.plot(x_positions, np.array(data), 'x', color = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "data.num_classes = 2\n",
    "# Klassen 0,1,2,4,5,6 werden zu Klasse 1, Klasse 3 wird zu Klasse 0\n",
    "y = torch.zeros_like(data.y)\n",
    "y[data.y == 3] = 1\n",
    "data.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks1 = list()\n",
    "for i in range(80):\n",
    "    mask1 = create_mask_from_pi(data, pi1)\n",
    "    val_mask1, train_mask1 = split_known_mask_into_val_and_train_mask(mask1)\n",
    "    masks1.append((None, train_mask1, val_mask1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_masks = masks1\n",
    "pi_true = pi1(data.x, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Eval \n",
    "IT_per_mask = 2\n",
    "NB_masks = len(choosen_masks)\n",
    "t_0 = time.time()\n",
    "noise_levels = [0, 0.1, 0.2, 0.4, 0.8, 1.1]\n",
    "all_models = dict()\n",
    "smn_models = [list() for _ in range(len(noise_levels))\n",
    "    \n",
    "for j, mask_tupel in enumerate(choosen_masks):\n",
    "    _, train_mask, val_mask = mask_tupel\n",
    "\n",
    "    # Trainiere jeweils N Modelle\n",
    "    for k in range(IT_per_mask):\n",
    "        for m, noise_level in enumerate(noise_levels):\n",
    "            print_status(j * IT_per_mask * len(noise_levels) + k * len(noise_levels) + m, NB_masks * IT_per_mask * len(noise_levels), t_0)\n",
    "            y_noise = disturb_y(data.y, noise_level)\n",
    "            pi_est, loss_list, acc_r = train_modelr(data.x, data.y, data.num_classes, train_mask+val_mask, y_noise, NB_IT=30, expectation='fast')\n",
    "\n",
    "            smn_models[m].append(loss_list[-1])\n",
    "        all_models[1] = (smn_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(all_models, \n",
    "          colors = [(0.3 + i * 0.0875, 0.8 - i * 0.1, 0.2 - i * 0.01) for i in range(8)], \n",
    "          names = [0, 0.1, 0.2, 0.4, 0.8, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
