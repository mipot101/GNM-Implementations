{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset on harddrive.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "\n",
    "from GNM_Toolbox.tools.tools import *\n",
    "from GNM_Toolbox.gnm import *\n",
    "from GNM_Toolbox.data.dataloader import *\n",
    "\n",
    "dataset = load_dataset('Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# Gesucht wird eine Liste l von Indizes, sodass für i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][0])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][0])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def h0(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi0(X, y):\n",
    "    y0 = F.one_hot(y, 2).type(X.dtype)\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(35.)), 1, torch.tensor([0, 1.6])\n",
    "    return torch.sigmoid(a0 + a1 * h0(X) + a2 @ y0.T)\n",
    "\n",
    "def h1(x):\n",
    "    a0, a1, a2, a3 = 18, 4, 5, 6\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi1(X, y):\n",
    "    y0 = F.one_hot(y, 2)\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(25.)), 2., torch.tensor([2, 4])\n",
    "    return torch.sigmoid(a0 + a1 * h1(X) + a2 @ y0.T)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def calculate_lambda(train_mask, y):\n",
    "    a = 0 # Anzahl an Klasse 0\n",
    "    b = 0 # Anzahl an Klasse 1\n",
    "    for yy in y[train_mask]:\n",
    "        if yy == 0:\n",
    "            a += 1\n",
    "        elif yy == 1:\n",
    "            b += 1\n",
    "    return b/a\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)\n",
    "\n",
    "def disturb_y(y, probability): # y must have 2 classes\n",
    "    y_dis = torch.zeros_like(y)\n",
    "    for i in range(len(y)):\n",
    "        if np.random.rand(1) < probability:\n",
    "            y_dis[i] = 0 if np.random.rand(1) > 0.5 else 1\n",
    "        else:\n",
    "            y_dis[i] = y[i]\n",
    "                \n",
    "    return F.one_hot(y_dis, 2)\n",
    "\n",
    "# root mean squared error\n",
    "def RMSE(pi_est, pi_true):\n",
    "    return torch.sqrt(F.mse_loss(pi_true, pi_est.view(pi_true.shape)))\n",
    "\n",
    "# mean squared error\n",
    "def MSE(pi_est, pi_true):\n",
    "    return F.mse_loss(pi_true, pi_est)\n",
    "\n",
    "# weighted mean squared error\n",
    "def WMSE(pi_est, pi_true, weight):\n",
    "    return torch.mean(weight * (pi_est - pi_true) ** 2)\n",
    "\n",
    "\n",
    "# mean root error\n",
    "def MRE(pi_est, pi_true):\n",
    "    return torch.mean(torch.pow(abs(pi_est.view(pi_true.shape) - pi_true), 0.5))\n",
    "\n",
    "# berechnet Gewichtungen für weighted mean square error\n",
    "def calc_inverse_weights(pi_real):\n",
    "    bins = torch.zeros(len(pi_real)).type(torch.float)\n",
    "    pi = pi_real.detach().numpy()\n",
    "    # Count \n",
    "    for p in pi_real:\n",
    "        bins[int(p*100)] += 1\n",
    "    bins = 1/bins\n",
    "    bins[bins == (torch.tensor(1.)/0)] = 999999999\n",
    "    return torch.sqrt(bins)\n",
    "\n",
    "def eval_pi(pi_true, pi_est, diff=0.01):\n",
    "    pi_diff = abs(pi_true.view(pi_est.shape)-pi_est)\n",
    "    pi_binar = [(p < diff) for p in pi_diff]\n",
    "    return sum(pi_binar)/(1. * pi_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "data.num_classes = 2\n",
    "# Klassen 0,1,2,4,5,6 werden zu Klasse 1, Klasse 3 wird zu Klasse 0\n",
    "y = torch.zeros_like(data.y)\n",
    "y[data.y == 3] = 1\n",
    "data.y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verteilung von $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 50)\n",
    "pi_true = pi1(data.x, data.y)\n",
    "plt.hist(pi_true[data.y == 1], bins, alpha=0.6, color='red', edgecolor='black', label='1');\n",
    "plt.hist(pi_true[data.y == 0], bins, alpha=0.6, color='blue', edgecolor='black', label='0');\n",
    "plt.legend();\n",
    "mask = create_mask_from_pi(data, pi1)\n",
    "print('M1 = {:.3f} \\nM2 = {:.3f} \\nPerc = {:.3f}'.format(torch.mean(pi_true[mask]), \n",
    "                                            torch.mean(pi_true[mask.logical_not()]),\n",
    "                                            sum(mask)/(1. * len(data.y))))\n",
    "plt.figure()\n",
    "plt.hist(pi_true[(data.y == 1) & mask], bins, alpha=0.6, color='red', edgecolor='black', label='1');\n",
    "plt.hist(pi_true[(data.y == 0) & mask], bins, alpha=0.6, color='blue', edgecolor='black', label='0');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden wird überprüft, wie gut der MSE werden kann, wenn man eine Konstante als Schätzer wählt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle 80 Masken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks1 = list()\n",
    "for i in range(80):\n",
    "    mask1 = create_mask_from_pi(data, pi1)\n",
    "    val_mask1, train_mask1 = split_known_mask_into_val_and_train_mask(mask1)\n",
    "    masks1.append((None, train_mask1, val_mask1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysiere $\\textit{Model 1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3709e-02, 6.5938e-02, 9.1287e-02,  ..., 3.1623e+04, 3.1623e+04,\n",
       "        3.1623e+04])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choosen_masks = {1: masks1}\n",
    "pi_true = pi1(data.x, data.y)\n",
    "weights = calc_inverse_weights(pi_true)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysiere wie gut $L_2$  $\\pi$ approximiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160/160) |████████████████████| (3h 49min 46sec|1min 26sec|1min 26sec)                                     \r"
     ]
    }
   ],
   "source": [
    "# Eval \n",
    "IT_per_mask = 2\n",
    "NB_masks = len(choosen_masks[1])\n",
    "M = len(choosen_masks)\n",
    "t_0 = time.time()\n",
    "noise_levels = [0, 0.1, 0.2, 0.4, 0.8, 1.1]\n",
    "all_models = dict()\n",
    "\n",
    "# Iteriere über Masken\n",
    "for i, l in enumerate(choosen_masks):\n",
    "    sms_models = list() # SM Standard\n",
    "    smn_models = [list() for _ in range(len(noise_levels))] # change to len(noise_levels)\n",
    "    \n",
    "    for j, mask_tupel in enumerate(choosen_masks[l]):\n",
    "        _, train_mask, val_mask = mask_tupel\n",
    "\n",
    "        # Trainiere jeweils N Modelle\n",
    "        for k in range(IT_per_mask):\n",
    "            print_status(i * NB_masks * IT_per_mask + j * IT_per_mask + k, M * NB_masks * IT_per_mask, t_0)\n",
    "            for m, noise_level in enumerate(noise_levels):\n",
    "                y_noise = disturb_y(data.y, noise_level)\n",
    "                pi_est, loss_list, acc_r, _ = train_modelr4(data.x, data.y, data.num_classes, train_mask, val_mask, y_noise, NB_IT=30, expectation='other')\n",
    "                \n",
    "                #acc_pi = eval_pi(pi_est, pi_true, diff=0.02)\n",
    "                \n",
    "                smn_models[m].append(loss_list[-1])\n",
    "        all_models[l] = (smn_models)\n",
    "        #pickle_write('l2_analysis-noise-1/run-{}.pkl'.format(i), all_models)\n",
    "    all_models[l] = (smn_models)\n",
    "    #pickle_write('l2_analysis-noise-1/run-{}.pkl'.format(i), all_models)\n",
    "pickle_write('l2-improve-cora.pkl', all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternative_boxplot(data, x_position, x_width, color):\n",
    "    # data: list of floats\n",
    "    # x_postition: float\n",
    "    # x_width: float\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    print('{}:{}'.format(sum([1 for d in data if d > mean]), sum([1 for d in data if d < mean])))\n",
    "    noise = np.random.rand(N)\n",
    "    x_positions = - 1/2. + noise\n",
    "    plt.plot(x_positions, np.array(data), '.', color = color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = all_models[1][0]\n",
    "\n",
    "for it, loss in models:\n",
    "    noise = np.random.rand(1)\n",
    "    x_position = - 1/2. + noise\n",
    "    if loss > 400:\n",
    "        plt.plot(x_position, loss, '.', color = 'red')\n",
    "    else:\n",
    "        plt.plot(x_position, loss, '.', color = 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erkenntnis:\n",
    "\n",
    "Es scheint nötig zu sein, dass die gegebenen Daten tatsächlich eine signifikant höhere Wahrscheinlichkeit haben, gegeben zu sein. \n",
    "\n",
    "Zuvor war das Problem, dass der Mittelwert der gegebenen Daten sehr klein war (ca. 0.06) und der Mittelwert der nicht gegeben Daten kaum kleiner (ca. 0.05).\n",
    "\n",
    "Dieses Problem wurde nun behoben mit Werten (ca. 0.4 und ca. 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Experiment wird überprüft, wie gut $L_2$ $\\pi$ approximiert und welchen Einfluss Noise darauf hat.\n",
    "\n",
    "Dazu werden Netze mithilfe von $L_2$ trainiert. Es werden gelegentlich Klassenzugehörigkeiten gewechselt. Der Wert der Noise beschreibt dabei, wie wahrscheinlich es ist, dass die Klassenzugegörigkeit eines Knotens gewechselt wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...\n",
    "\n",
    "Wenn ich train_modelr3 nutze, ergibt jedes zweite Training ein Model mit Genauigkeit gegen 0.\n",
    "\n",
    "Jedes andere zweite Training hingegen, ergibt Genauigkeiten um die 65%, was schlecht, aber vernünftig erscheint.\n",
    "\n",
    "Ich überprüfe nun, ob sich das ändert, wenn ich mit train_modelr trainiere."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
