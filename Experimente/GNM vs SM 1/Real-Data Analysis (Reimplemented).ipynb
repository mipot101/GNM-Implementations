{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset on harddrive.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "\n",
    "from GNM_Toolbox.tools.tools import *\n",
    "from GNM_Toolbox.gnm import *\n",
    "from GNM_Toolbox.data.dataloader import *\n",
    "\n",
    "dataset = load_dataset('Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# Gesucht wird eine Liste l von Indizes, sodass für i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][0])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][0])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi_test(X, y):\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(35.)), 1, 1.6\n",
    "    return torch.sigmoid(a0 + a1 * h(X) + a2 * y)\n",
    "\n",
    "def pi_complicated(X, y):\n",
    "    tmp = torch.sum(X,axis=1) \n",
    "    h = torch.exp(tmp/13-4)-(tmp-15)/15\n",
    "    pi = 1/(1+35*np.exp(h[:]-1.6*y[:]))\n",
    "    return pi\n",
    "\n",
    "def pi_simple(x, y):\n",
    "    a = 0\n",
    "    b = 1\n",
    "    return torch.sigmoid(a + b*y)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def calculate_lambda(train_mask, y):\n",
    "    a = 0 # Anzahl an Klasse 0\n",
    "    b = 0 # Anzahl an Klasse 1\n",
    "    for yy in y[train_mask]:\n",
    "        if yy == 0:\n",
    "            a += 1\n",
    "        elif yy == 1:\n",
    "            b += 1\n",
    "    return b/a\n",
    "\n",
    "def time_to_string(i):\n",
    "    # float i\n",
    "    hours = int(i/3600)\n",
    "    i -= hours * 3600\n",
    "    minutes = int(i/60)\n",
    "    i -= minutes * 60\n",
    "    seconds = int(i)\n",
    "    if hours > 0:\n",
    "        return '{}h {}min {}sec'.format(hours, minutes, seconds)\n",
    "    elif minutes > 0:\n",
    "        return '{}min {}sec'.format(minutes, seconds)\n",
    "    else:\n",
    "        return '{:.2f}sec'.format(i)\n",
    "\n",
    "def print_status(i, N, starttime = None):\n",
    "    # Es wird angenommen, dass i von 0 bis N-1 läuft\n",
    "    # Länge Ladebalken = 20\n",
    "    l = 20\n",
    "    done = int(i/(N-1) * l)\n",
    "    counterstring = '({}/{})'.format(i+1, N)\n",
    "    barstring = '|'+u'\\u2588'*done + ' '*(l-done)+'|'\n",
    "    if starttime is None:\n",
    "        print('{} {}'.format(counterstring, barstring), end='\\r')\n",
    "    else:\n",
    "        t_1 = time.time()\n",
    "        time_spent = t_1 - starttime\n",
    "        iterations_done = i\n",
    "        iterations_to_go = N-i-1\n",
    "        if iterations_done == 0:\n",
    "            time_per_iteration = 0\n",
    "        else:\n",
    "            time_per_iteration = time_spent/iterations_done\n",
    "        time_to_go = time_per_iteration * iterations_to_go\n",
    "        \n",
    "        time_string = '({}|{}|{})'.format(time_to_string(time_spent), time_to_string(time_to_go), time_to_string(time_per_iteration))\n",
    "        \n",
    "        print('{} {} {}'.format(counterstring, barstring, time_string), end='\\r')\n",
    "        \n",
    "def print_double_status(i, N, j, M, starttime = None):\n",
    "    # Es wird angenommen, dass i von 0 bis N-1 läuft und j von 0 bis M-1\n",
    "    # Länge Ladebalken = 20\n",
    "    l = 20\n",
    "    done = int(i/(N-1) * l)\n",
    "    counterstring = '({}/{})'.format(i+1, N)\n",
    "    barstring = '|'+u'\\u2588'*done + ' '*(l-done)+'|'\n",
    "    if starttime is None:\n",
    "        print('{} {}               '.format(counterstring, barstring), end='\\r')\n",
    "    else:\n",
    "        t_1 = time.time()\n",
    "        time_spent = t_1 - starttime\n",
    "        iterations_done = i+1\n",
    "        iterations_to_go = N-i-1\n",
    "        time_per_iteration = time_spent/iterations_done\n",
    "        time_to_go = time_per_iteration * iterations_to_go\n",
    "        \n",
    "        time_string = '({}|{}|{})             '.format(time_to_string(time_spent), time_to_string(time_to_go), time_to_string(time_per_iteration))\n",
    "        \n",
    "        print('{} {} {}               '.format(counterstring, barstring, time_string), end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'>\n",
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "# Set up data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(type(data))\n",
    "data.num_classes = 2\n",
    "# Klassen 0,1,2,4,5,6 werden zu Klasse 1, Klasse 3 wird zu Klasse 0\n",
    "y = torch.zeros_like(data.y)\n",
    "y[data.y == 3] = 1\n",
    "data.y = y\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find masks such that lambda has specific values\n",
    "targets = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7]\n",
    "masks = dict()\n",
    "worst_allowed_diff = 0.005\n",
    "worst_diff = 1\n",
    "\n",
    "for t in targets:\n",
    "    masks[t] = None\n",
    "    \n",
    "i = 0\n",
    "while worst_diff > worst_allowed_diff:\n",
    "    i += 1\n",
    "    known_mask = create_mask_from_pi(data, pi_complicated)\n",
    "    val_mask, train_mask = split_known_mask_into_val_and_train_mask(known_mask)\n",
    "    l = calculate_lambda(train_mask, data.y)\n",
    "    \n",
    "    # Update masks\n",
    "    for t in targets:\n",
    "        diff = abs(l - t)\n",
    "        best = masks[t]\n",
    "        if best is None:\n",
    "            masks[t] = (l, train_mask, val_mask)\n",
    "        elif abs(best[0] - t) > diff:\n",
    "            masks[t] = (l, train_mask, val_mask)\n",
    "    \n",
    "    # Update worst_diff\n",
    "    worst_diff_old = worst_diff\n",
    "    worst_diff = 0\n",
    "    for t in targets:\n",
    "        diff = abs(t - masks[t][0])\n",
    "        if diff > worst_diff:\n",
    "            worst_diff = diff\n",
    "    print('At iteration {:6} worst_diff is {:.4f}'.format(i, worst_diff), end='\\r')\n",
    "\n",
    "# Safe masks\n",
    "with open('masks.pkl', 'ab') as output:\n",
    "    pickle.dump(masks, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fitting subset of masks\n",
    "with open('masks.pkl', 'rb') as instream:\n",
    "    all_masks = pickle.load(instream)\n",
    "subset = [1, 1.2, 1.5, 1.7, 2, 2.2, 2.5]\n",
    "masks = {k: all_masks[k] for k in subset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840/840) |████████████████████| (3h 49min 33sec|0.00sec|16.42sec))))))))\r"
     ]
    }
   ],
   "source": [
    "# Real Data analysis with GNM and SM\n",
    "N = 120\n",
    "M = len(masks)\n",
    "t_0 = time.time()\n",
    "\n",
    "all_models = dict()\n",
    "\n",
    "# Iteriere über Masken\n",
    "for i, h in enumerate(masks):\n",
    "    var_lambda, train_mask, val_mask = masks[h]\n",
    "    gnm_models = list()\n",
    "    sm_models = list()\n",
    "    \n",
    "    # Trainiere jeweils N Modelle\n",
    "    for j in range(N):\n",
    "        print_status(i*N + j, N*M, t_0)\n",
    "        gnm_models.append(train_net_with_gnm(data, train_mask, val_mask)[1:])\n",
    "        sm_models.append(train_one_net(data, train_mask, val_mask)[1:])\n",
    "    all_models[var_lambda] = (gnm_models, sm_models)\n",
    "    \n",
    "with open('real-data-results.pkl', 'ab') as output:\n",
    "    pickle.dump(all_models, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Data analysis with SM and SM5\n",
    "N = 30\n",
    "M = len(masks)\n",
    "t_0 = time.time()\n",
    "\n",
    "all_models = dict()\n",
    "\n",
    "# Iteriere über Masken\n",
    "for i, h in enumerate(masks):\n",
    "    var_lambda, train_mask, val_mask = masks[h]\n",
    "    sm5_models = list()\n",
    "    sm_models = list()\n",
    "    \n",
    "    # Trainiere jeweils N Modelle\n",
    "    for j in range(N):\n",
    "        print_status(i*N + j, N*M, t_0)\n",
    "        sm5_models.append(train_one_net(data, train_mask, val_mask))\n",
    "        sm_models.append(train_net(data, train_mask, val_mask))\n",
    "    all_models[var_lambda] = (sm5_models, sm_models)\n",
    "    \n",
    "with open('real-data-results-3.pkl', 'ab') as output:\n",
    "    pickle.dump(all_models, output, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
