{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Analyse Citeseer 2 class\n",
    "\n",
    "Um dieses Experiment selbst auszuf端hren, f端hre die Zellen von oben nach unten aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # Lokales Speichern von Objekten\n",
    "import keyboard\n",
    "from scipy import interpolate\n",
    "\n",
    "from GNM_Toolbox import *\n",
    "\n",
    "dataset = load_dataset('Citeseer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einige Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben sei eine target_list (a_0, a_1, a_2, ...)\n",
    "# und eine out_list ((b_0, x), (b_1, x), (b_2, x), (b_3, x), ...)\n",
    "# Gesucht wird eine Liste l von Indizes, sodass f端r i < len(target_list): abs(target_list[i] - out_list[l[i]][0]) minimal ist\n",
    "def find_each_nearest(target_list, out_list):\n",
    "    # Each list is expected to be sorted\n",
    "    i, j = 0, 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        diff_0 = abs(target_list[i] - out_list[j][0])\n",
    "        diff_1 = abs(target_list[i] - out_list[j+1][0])\n",
    "        \n",
    "        if diff_0 >= diff_1:\n",
    "            j += 1\n",
    "        elif diff_0 < diff_1:\n",
    "            result.append(j)\n",
    "            i += 1\n",
    "        if i >= len(target_list):\n",
    "            return result\n",
    "        if j+1 >= len(out_list):\n",
    "            while i < len(target_list):\n",
    "                result.append(j)\n",
    "                i += 1\n",
    "            return result\n",
    "            \n",
    "def get_best_values_indices(targets, lambdas):\n",
    "    lambdas.sort(key = lambda x: x[0])\n",
    "    return find_each_nearest(targets, lambdas)\n",
    "\n",
    "def create_mask_from_pi(data, pi):\n",
    "    p = pi(data.x, data.y)\n",
    "    mask = torch.tensor((np.random.binomial(size = p.shape[0], n = 1, p = p) == 1))        \n",
    "    return mask.bool()\n",
    "\n",
    "def split_known_mask_into_val_and_train_mask(known, ratio=0.8):\n",
    "    val_mask = torch.zeros_like(known) == 1\n",
    "    train_mask = torch.zeros_like(known) == 1\n",
    "    for i in range(len(known)):\n",
    "        if known[i] == True:\n",
    "            if np.random.binomial(1, ratio) == 1:\n",
    "                train_mask[i] = True\n",
    "            else:\n",
    "                val_mask[i] = True\n",
    "    return val_mask, train_mask\n",
    "\n",
    "def calculate_lambda(train_mask, y):\n",
    "    a = 0 # Anzahl an Klasse 0\n",
    "    b = 0 # Anzahl an Klasse 1\n",
    "    for yy in y[train_mask]:\n",
    "        if yy == 0:\n",
    "            a += 1\n",
    "        elif yy == 1:\n",
    "            b += 1\n",
    "    return b/a\n",
    "        \n",
    "def insert_into_list(l, item, t):\n",
    "    # l list, i item to insert, target\n",
    "    def diff(a, b):\n",
    "        return abs(a-b)\n",
    "    N = len(l)\n",
    "    if N == 0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    d = diff(t, item[0])\n",
    "    d_0 = diff(t, l[0][0])\n",
    "    if d <= d_0:\n",
    "        l.insert(0, item)\n",
    "        return\n",
    "    for i in range(N-1):\n",
    "        d_0 = diff(t, l[i][0])\n",
    "        d_1 = diff(t, l[i+1][0])\n",
    "        if d_0 <= d and d <= d_1:\n",
    "            l.insert(i+1, item)\n",
    "            return\n",
    "    l.append(item)\n",
    "    \n",
    "def setBoxColors(bp, edge_color='red', face_color='red'):\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=edge_color)\n",
    "    plt.setp(bp[\"boxes\"], facecolor=face_color)\n",
    "    plt.setp(bp[\"fliers\"], markeredgecolor=face_color)\n",
    "    \n",
    "def plot_data(all_models, colors, names, dist = [-0.15, 0.15]):\n",
    "    M = len(all_models)\n",
    "    \n",
    "    # Set up \n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    ax = plt.axes()\n",
    "    minimum = 1\n",
    "    maximum = 0\n",
    "    for i, l in zip(range(1, M+1), all_models):\n",
    "        for models, color, (dd, d) in zip(all_models[l], colors, enumerate(dist)):\n",
    "            acc = list()\n",
    "            for model in models:\n",
    "                if type(model[1]) == type(list()):\n",
    "                    acc.append(model[1][len(model[1])-1])\n",
    "                else:\n",
    "                    acc.append(model[1])\n",
    "            if dd == 0:\n",
    "                print('\\\\hline')\n",
    "                print('{} & \\\\textbf{{NLL}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{}}} \\\\\\\\'.format(l, np.mean(acc), np.format_float_scientific(np.var(acc), precision=2)))\n",
    "            elif dd == 1:\n",
    "                print('& $\\\\textbf{{L}}_1$ & \\\\textbf{{{:.3f}}} & \\\\textbf{{{}}} \\\\\\\\'.format(np.mean(acc), np.format_float_scientific(np.var(acc), precision=2)))\n",
    "            else:\n",
    "                sigma = [0, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02]\n",
    "                print('& $L_1$ + $\\\\sigma$ = {} & {:.3f} & {} \\\\\\\\'.format(sigma[dd-1], np.mean(acc), np.format_float_scientific(np.var(acc), precision=2)))\n",
    "            \n",
    "            # Find min und max\n",
    "            if minimum > min(acc):\n",
    "                minimum = min(acc)\n",
    "            if maximum < max(acc):\n",
    "                maximum = max(acc)\n",
    "            bp = plt.boxplot([acc], positions = [i+d], widths = 0.5 / len(dist), patch_artist=True)\n",
    "            setBoxColors(bp, 'black', color)\n",
    "        \n",
    "    # Set x-axis labels\n",
    "    seperation_lines = [i + 0.5 for i in range(1, M)]\n",
    "    plt.vlines(seperation_lines, 0, 1, colors='grey', linestyles='dashed')\n",
    "    ax.set_xticks(list(range(1, M+1)))\n",
    "    ax.set_yticks([0.3, 0.4, 0.5, 0.6, 0.65, 0.7, 0.725, 0.75, 0.775, 0.8, 0.825, 0.85, 0.875, 0.9])\n",
    "    lambdas = list(all_models.keys())\n",
    "    lambdas.sort()\n",
    "    ax.set_xticklabels([int(l * 100)/100 for l in lambdas])\n",
    "    #plt.ylim(minimum - 0.01, maximum + 0.01)\n",
    "    plt.ylim(0.65, maximum + 0.01)\n",
    "    plt.xlim(0.4, M + 0.6)\n",
    "    \n",
    "    # draw temporary red and blue lines and use them to create a legend\n",
    "    helps = list()\n",
    "    for color in colors:\n",
    "        h, = plt.plot([1, 1], color=color)\n",
    "        helps.append(h)\n",
    "    ax.legend(helps, names, prop={'size': 16}) #plot.legend(loc=2, prop={'size': 6})\n",
    "    ax.grid(True, axis='y')\n",
    "    ax.set_xlabel(r'$\\lambda$')\n",
    "    ax.set_ylabel(r'Genauigkeit auf unbekannten Daten')\n",
    "    for h in helps:\n",
    "        h.set_visible(False)\n",
    "        \n",
    "\n",
    "def print_fitting(fitting_masks, i, num_masks):\n",
    "    k = fitting_masks.keys()\n",
    "    string = ''\n",
    "    for kk in k:\n",
    "        if fitting_masks[kk] <= num_masks:\n",
    "            string += ' {}'.format(fitting_masks[kk])\n",
    "        else:\n",
    "            string += ' {}+'.format(num_masks)\n",
    "    print(string + ' at iteration {}'.format(i), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informationen 端ber das Setup\n",
    "\n",
    "Citeseer Datasets besteht aus 6 Klassen. \n",
    "\n",
    "Die Verteilung der Knoten ist wie folgt 249, 590, 668, 701, 596, 523.\n",
    "\n",
    "Deshalb setzen wir die neue Klasse 0 als Klasse 3 und die neue Klasse 1 als die restlichen Klassen.\n",
    "\n",
    "Insgesamt haben wir 3327 Knoten mit je 3703 Features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    a0, a1, a2, a3 = 13, 4, 15, 15\n",
    "    return torch.exp(torch.sum(x, dim=1)/a0 - a1) - ((torch.sum(x, dim=1) - a2 ) / a3)\n",
    "    \n",
    "def pi(X, y):\n",
    "    a0, a1, a2 = -torch.log(torch.tensor(4.)), 1, -1\n",
    "    return torch.sigmoid(a0 + a1 * h(X) + a2 * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "y_tmp = data.y == 3\n",
    "data.y = torch.ones_like(data.y)\n",
    "data.y[y_tmp] = 0\n",
    "data.num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list()\n",
    "\n",
    "for i in range(1000):\n",
    "    mask = create_mask_from_pi(data, pi)\n",
    "    var_lambda = calculate_lambda(mask, data.y)\n",
    "    lambdas.append(var_lambda)\n",
    "    print('{:.3f}'.format(sum(mask)/(len(mask)*1.0)), end='\\r')\n",
    "    time.sleep(1)\n",
    "\n",
    "plt.hist(lambdas, bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finde passende Masken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find masks such that lambda has specific values\n",
    "targets = [1, 1.5, 2]\n",
    "masks = {t: list() for t in targets} # Safes actual masks\n",
    "num_fitting_masks = {t: 0 for t in targets} # num of masks which fit for a target\n",
    "targets_done = set() # Safes which targets have enough masks\n",
    "worst_allowed_diff = 0.01\n",
    "worst_diff = 1\n",
    "num_masks = 40 # num_masks_per_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "t_start = time.time()\n",
    "while worst_diff > worst_allowed_diff and i < 40000 and len(set(targets)-targets_done) > 0:\n",
    "    i += 1\n",
    "    known_mask = create_mask_from_pi(data, pi)\n",
    "    val_mask, train_mask = split_known_mask_into_val_and_train_mask(known_mask)\n",
    "    l = calculate_lambda(train_mask, data.y)\n",
    "    item = (l, train_mask, val_mask)\n",
    "    \n",
    "    # Update masks\n",
    "    for t in set(targets)-targets_done:\n",
    "        diff = abs(l - t)\n",
    "        masks_ind = masks[t]\n",
    "        if len(masks_ind) < num_masks:\n",
    "            insert_into_list(masks_ind, item, t)\n",
    "            if diff < worst_allowed_diff:\n",
    "                num_fitting_masks[t] += 1\n",
    "                print_fitting(num_fitting_masks, i, num_masks)\n",
    "                if num_fitting_masks[t] > num_masks:\n",
    "                    targets_done.add(t)\n",
    "        elif abs(masks_ind[num_masks-1][0] - t) > diff:\n",
    "            insert_into_list(masks_ind, item, t)\n",
    "            masks[t] = masks_ind[0:num_masks]\n",
    "            if diff < worst_allowed_diff:\n",
    "                num_fitting_masks[t] += 1\n",
    "                print_fitting(num_fitting_masks, i, num_masks)\n",
    "                if num_fitting_masks[t] > num_masks:\n",
    "                    targets_done.add(t)\n",
    "    \n",
    "    # Update worst_diff\n",
    "    worst_diff_old = worst_diff\n",
    "    worst_diff = 0\n",
    "    for t in set(targets)-targets_done:\n",
    "        length = len(masks[t])\n",
    "        diff = abs(t - masks[t][length-1][0])\n",
    "        if diff > worst_diff:\n",
    "            worst_diff = diff\n",
    "            \n",
    "# Safe masks\n",
    "#pickle_write('masks_citeseer_small.pkl', (masks, fitting_masks, targets_done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysiere on Loss Function $L_1$ tats辰chlich besser als NLL ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate actuall pi\n",
    "pi_true = pi(data.x, data.y)\n",
    "\n",
    "# Load masks\n",
    "all_masks = masks\n",
    "subset = [1, 1.5, 2]\n",
    "choosen_masks = {k: all_masks[k] for k in subset}\n",
    "\n",
    "# Drei Masken: 10, 15, 20\n",
    "# Acht +1 Noiselevel: 0, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval 'Perfect' Loss, 'Perfect' Loss with noise and NLL\n",
    "IT_per_mask = 4\n",
    "NB_masks = len(choosen_masks[1.0])\n",
    "M = len(choosen_masks)\n",
    "t_0 = time.time()\n",
    "noise_levels = [0, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02]\n",
    "all_models = dict()\n",
    "\n",
    "# Iteriere 端ber Masken\n",
    "for i, l in enumerate(choosen_masks):\n",
    "    sms_models = list() # SM Standard\n",
    "    smn_models = [list() for _ in range(9)] # SM Advanced with noises\n",
    "    \n",
    "    for j, mask_tupel in enumerate(choosen_masks[l]):\n",
    "        _, train_mask, val_mask = mask_tupel\n",
    "\n",
    "        # Trainiere jeweils N Modelle\n",
    "        for k in range(IT_per_mask):\n",
    "            print_status(i * NB_masks * IT_per_mask + j * IT_per_mask + k, M * NB_masks * IT_per_mask, t_0)\n",
    "            noise = torch.randn_like(pi_true)\n",
    "            for m, noise_level in enumerate(noise_levels):\n",
    "                pi = pi_true + noise_level * noise\n",
    "                smn_models[m].append((*train_one_net(data, \n",
    "                                                  train_mask, \n",
    "                                                  val_mask,\n",
    "                                                  loss_function=inverse_weighted_categorial_crossentropy_loss(pi[train_mask], reduction='mean'),\n",
    "                                                  val_loss_function=inverse_weighted_categorial_crossentropy_loss(pi[val_mask], reduction='mean'))[1:], j))\n",
    "            sms_models.append((*train_one_net(data, train_mask, val_mask)[1:], j))\n",
    "    all_models[l] = (sms_models, *smn_models)\n",
    "    \n",
    "#pickle_write('l1_analysis-citeseer_small.pkl', all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(all_models, \n",
    "          ('b', *[(0.3 + i * 0.0875, 0.8 - i * 0.1, 0.2 - i * 0.01) for i in range(9)]), \n",
    "          ['NLL', r'$L_1$ + $\\pi$', r'$L_1$ + $\\pi_{0.0025}$', r'$L_1$ + $\\pi_{0.005}$', r'$L_1$ + $\\pi_{0.0075}$', r'$L_1$ + $\\pi_{0.01}$', r'$L_1$ + $\\pi_{0.0125}$', r'$L_1$ + $\\pi_{0.015}$', r'$L_1$ + $\\pi_{0.0175}$', r'$L_1$ + $\\pi_{0.02}$'], \n",
    "          dist = [-0.4, -0.31, -0.22, -0.13, -0.04, 0.04, 0.13, 0.22, 0.31, 0.4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
